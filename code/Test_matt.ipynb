{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utilities.proj1_helpers import load_csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,) (250000, 30) (250000,)\n"
     ]
    }
   ],
   "source": [
    "train_data = load_csv_data(\"data/train.csv\")\n",
    "y, x, ids = train_data[0], train_data[1], train_data[2]\n",
    "N, D = x.shape\n",
    "print(y.shape, x.shape, ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = load_csv_data(\"data/test.csv\")\n",
    "y_train, x_train, ids_train = train_data[0], train_data[1], train_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from regression.linear_models import *\n",
    "from regression.stochastic_models import *\n",
    "from utilities.cross_validation import cross_validation, build_k_indices, split_data\n",
    "from regression.loss import compute_rmse_loss\n",
    "from utilities.pca import compute_pca\n",
    "from utilities.stochastic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Params to bruteforce\n",
    "lambdas = np.logspace(-5, 1, 10)\n",
    "degrees = np.arange(1, 8, 1)\n",
    "k_folds = 4\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std = np.std(x, axis=0)\n",
    "x /= np.ones((N, 1)).dot(std.reshape((1, D)))\n",
    "x_reduced, vectors = compute_pca(x)\n",
    "\n",
    "std = np.std(x_train, axis=0)\n",
    "x_train /= np.ones((N, 1)).dot(std.reshape((1, D)))\n",
    "g = np.mean(x_train, axis=0)\n",
    "x_train -= g\n",
    "x_train_reduced = x_train.dot(np.array(vectors).T) + np.ones((N, 1)).dot(g[:len(vectors)].reshape((1, len(vectors))))\n",
    "indices = np.random.randint(0, high=len(x), size=((1, 500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter3D(x_reduced[indices, 0], x_reduced[indices, 0], x_reduced[indices, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_w(num_intervals):\n",
    "    \"\"\"Generate a grid of values for w0 and w1.\"\"\"\n",
    "    w0 = np.linspace(-100, 200, num_intervals)\n",
    "    w1 = np.linspace(-100, 200, num_intervals)\n",
    "    w2 = np.linspace(-100, 200, num_intervals)\n",
    "    return w0, w1, w2\n",
    "\n",
    "\n",
    "def get_best_parameters(w0, w1, w2, losses):\n",
    "    \"\"\"Get the best w from the result of grid search.\"\"\"\n",
    "    min_row, min_col, min_slice = np.unravel_index(np.argmin(losses), losses.shape)\n",
    "    return losses[min_row, min_col, min_slice], w0[min_row], w1[min_col], w2[min_slice]\n",
    "\n",
    "def grid_search(y, tx, w0, w1, w2):\n",
    "    \"\"\"Algorithm for grid search.\"\"\"\n",
    "    losses = np.zeros((len(w0), len(w1), len(w2)))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss for each combination of w0, w1 and w2.\n",
    "    # ***************************************************\n",
    "    for i in range(0, len(w0)):\n",
    "        for j in range(0, len(w1)):\n",
    "            for k in range(0, len(w2)):\n",
    "                losses[i, j, k] = compute_rmse_loss(y, tx, np.array([w0[i], w1[j], w2[k]]))\n",
    "    return losses\n",
    "\n",
    "w0, w1, w2 =  generate_w(30)\n",
    "losses = grid_search(y, x_reduced, w0, w1, w2)\n",
    "print(get_best_parameters(w0, w1, w2, losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_loss = 1e100\n",
    "best_params = (-1, -1)\n",
    "k_indices = build_k_indices(y, k_folds, seed)\n",
    "degree = 1\n",
    "\n",
    "D = x_reduced.shape[1]\n",
    "w0 = np.array([0 for i in range(D)])\n",
    "\n",
    "for l in lambdas:\n",
    "    w, loss_tr = stochastic_gradient_descent(y, x_reduced, w0, 1000, 1e-10, compute_rmse_loss, compute_mse_gradient)\n",
    "    loss_te = compute_rmse_loss(y_train, x_train_reduced, w, lambda_=l)\n",
    "    if loss_te < best_loss:\n",
    "        best_loss = loss_te\n",
    "        best_params = (l, degree)\n",
    "\n",
    "    print(\"l={}, d={}: train {}, test {}\".format(l, degree, loss_tr, loss_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(best_params, best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sums_(n_numbers, d):\n",
    "    if n_numbers <= 1:\n",
    "        result = d\n",
    "    else:\n",
    "        result = np.zeros((0, n_numbers))\n",
    "        for i in range(d, -1, -1):\n",
    "            rc = sums_(n_numbers - 1, d - i)\n",
    "            print(rc, result.shape)\n",
    "            result = np.vstack((result, np.hstack((i * rc, rc))))\n",
    "    return result\n",
    "\n",
    "X = x_reduced\n",
    "n_obs, n_vars = X.shape\n",
    "max_degree  = 4     # order of polynomial\n",
    "\n",
    "stacked = np.zeros((0, n_vars)) #this will collect all the coefficients...    \n",
    "for d in range(1, max_degree+1):\n",
    "    stacked = np.vstack((stacked, sums_(n_vars, d)))\n",
    "\n",
    "newX = np.zeros((X.shape[0], stacked.shape[0]))\n",
    "for i in range(1, stacked.shape[0]+1):\n",
    "    accumulator = np.ones((n_obs, 1))\n",
    "    for j in range(1, n_vars+1):\n",
    "        accumulator = accumulator * X[:, j-1]**stacked[i-1, j-1]\n",
    "    newX[:, i-1] = accumulator\n",
    "\n",
    "                                \n",
    "                                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
